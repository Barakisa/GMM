{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 - as laboratorinis darbas (individualus)\n",
    "\n",
    "Nojus Džiaugys s2110552\n",
    "\n",
    "Pasirinktos klases: Jelyfish, Isopod, Snail\n",
    "\n",
    "Modelis: resnet50\n",
    "\n",
    "version 1.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pprint\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Commons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding a device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def use_device():\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "    return device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHOSEN_CLASSES = sorted([\"Jellyfish\", \"Snail\", \"Isopod\"])\n",
    "THRESHOLD = 0.7\n",
    "BATCH_SIZE = 10\n",
    "DATA_DIR = \"data3\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download images\n",
    "\n",
    "should only be run once, or when new classes get added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download started...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-05  14:34:04 INFO Downloading 379 train images for class 'jellyfish'\n",
      "100%|██████████| 379/379 [00:15<00:00, 24.62it/s]\n",
      "2024-03-05  14:34:20 INFO Downloading 414 train images for class 'snail'\n",
      "100%|██████████| 414/414 [00:14<00:00, 29.18it/s]\n",
      "2024-03-05  14:34:34 INFO Downloading 72 train images for class 'isopod'\n",
      "100%|██████████| 72/72 [00:03<00:00, 21.26it/s]\n",
      "2024-03-05  14:34:39 INFO Downloading 23 validation images for class 'jellyfish'\n",
      "100%|██████████| 23/23 [00:01<00:00, 11.54it/s]\n",
      "2024-03-05  14:34:41 INFO Downloading 31 validation images for class 'snail'\n",
      "100%|██████████| 31/31 [00:02<00:00, 15.05it/s]\n",
      "2024-03-05  14:34:43 INFO Downloading 5 validation images for class 'isopod'\n",
      "100%|██████████| 5/5 [00:01<00:00,  3.96it/s]\n",
      "2024-03-05  14:34:48 INFO Downloading 54 test images for class 'jellyfish'\n",
      "100%|██████████| 54/54 [00:03<00:00, 16.59it/s]\n",
      "2024-03-05  14:34:51 INFO Downloading 100 test images for class 'snail'\n",
      "100%|██████████| 100/100 [00:04<00:00, 20.03it/s]\n",
      "2024-03-05  14:34:56 INFO Downloading 5 test images for class 'isopod'\n",
      "100%|██████████| 5/5 [00:01<00:00,  3.58it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'jellyfish': {'images_dir': 'data3\\\\jellyfish\\\\images'},\n",
       " 'snail': {'images_dir': 'data3\\\\snail\\\\images'},\n",
       " 'isopod': {'images_dir': 'data3\\\\isopod\\\\images'}}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from openimages.download import download_dataset\n",
    "\n",
    "data_dir_base = \"data\"\n",
    "number_for_samples = 1000\n",
    "i = 1\n",
    "while os.path.exists(f\"{data_dir_base}{i}\"):\n",
    "    i += 1    \n",
    "os.makedirs(f\"{data_dir_base}{i}\")\n",
    "\n",
    "print(\"Download started...\")\n",
    "download_dataset(f\"{data_dir_base}{i}\", CHOSEN_CLASSES, limit=number_for_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = use_device()\n",
    "model = torchvision.models.resnet50(weights=ResNet50_Weights.DEFAULT).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Image transformer for model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run model\n",
    "for one image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: Isopod, Probability: 0.95%\n",
      "Class: Jellyfish, Probability: 0.06%\n",
      "Class: Snail, Probability: 0.03%\n"
     ]
    }
   ],
   "source": [
    "image = Image.open('data1\\spider\\images\\\\0a03dbf1a69f2bec.jpg')\n",
    "\n",
    "# Model runs on device\n",
    "output = model(all_transforms(image).unsqueeze(0).to(device))\n",
    "output = output.squeeze().cpu()\n",
    "# idx = torch.argmax(output)\n",
    "# print(torch.argmax(output))\n",
    "\n",
    "\n",
    "classes = open('general_classification.txt', 'r').readlines()\n",
    "# chatgpt\n",
    "probabilities = torch.nn.functional.softmax(output, dim=0)\n",
    "for class_name in CHOSEN_CLASSES:\n",
    "    class_idx = classes.index((class_name + '\\n').lower())\n",
    "    class_prob = probabilities[class_idx]\n",
    "    print(f\"Class: {class_name}, Probability: {class_prob.item() * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data loader\n",
    "makes a dataset of all images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an ImageFolder dataset\n",
    "dataset = torchvision.datasets.ImageFolder(root=DATA_DIR, transform=all_transforms)\n",
    "\n",
    "# Create a DataLoader for the dataset\n",
    "dataset_loader = torch.utils.data.DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculates metrics\n",
    "based on predictions and actual truths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(ground_truth, predictions, threshold=THRESHOLD):\n",
    "    # Convert predictions to binary values based on the threshold\n",
    "    predictions = (np.array(predictions) >= threshold).astype(np.float64)\n",
    "\n",
    "    # Dictionary to store metrics for each chosen class\n",
    "    metrics_per_class = {}\n",
    "\n",
    "    # Lists to store True Positives, True Negatives, False Positives, and False Negatives for each class\n",
    "    Tp = [0] * len(CHOSEN_CLASSES)\n",
    "    Tn = [0] * len(CHOSEN_CLASSES)\n",
    "    Fp = [0] * len(CHOSEN_CLASSES)\n",
    "    Fn = [0] * len(CHOSEN_CLASSES)\n",
    "\n",
    "    # Loop through each batch of ground truth and predictions\n",
    "    for batch_truths, batch_predictions in zip(ground_truth, predictions):\n",
    "        # Loop through each sample in the batch\n",
    "        for i in range(len(batch_truths)):\n",
    "            # Loop through each class\n",
    "            for j in range(len(batch_truths[i])):\n",
    "                # Update counts for True Positives, True Negatives, False Positives, and False Negatives\n",
    "                Tp[j] += np.bitwise_and(batch_truths[i][j] == 1, batch_predictions[i][j] == 1)\n",
    "                Tn[j] += np.bitwise_and(batch_truths[i][j] == 0, batch_predictions[i][j] == 0)\n",
    "                Fp[j] += np.bitwise_and(batch_truths[i][j] == 0, batch_predictions[i][j] == 1)\n",
    "                Fn[j] += np.bitwise_and(batch_truths[i][j] == 1, batch_predictions[i][j] == 0)\n",
    "\n",
    "    # Calculate and store metrics for each chosen class\n",
    "    for i in range(len(CHOSEN_CLASSES)):\n",
    "        tp = Tp[i]\n",
    "        tn = Tn[i]\n",
    "        fp = Fp[i]\n",
    "        fn = Fn[i]\n",
    "\n",
    "        metrics_per_class[CHOSEN_CLASSES[i]] = {\n",
    "            'accuracy': (tp + tn) / (tp + tn + fp + fn),\n",
    "            'recall': (tp) / (tp + fn),\n",
    "            'precision': (tp) / (tp + fp)\n",
    "        }\n",
    "\n",
    "        # Calculate F1 score and add it to the metrics dictionary\n",
    "        m = metrics_per_class[CHOSEN_CLASSES[i]]\n",
    "        m['f1'] = 2 * (m['precision'] * m['recall']) / (m['precision'] + m['recall'])\n",
    "\n",
    "    return metrics_per_class\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run model on all images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 0.7\n",
      "\n",
      "Class: Isopod\n",
      "{'accuracy': 0.925207756232687,\n",
      " 'f1': 0.024096385542168676,\n",
      " 'precision': 1.0,\n",
      " 'recall': 0.012195121951219513}\n",
      "\n",
      "\n",
      "Class: Jellyfish\n",
      "{'accuracy': 0.6195752539242844,\n",
      " 'f1': 0.176,\n",
      " 'precision': 1.0,\n",
      " 'recall': 0.09649122807017543}\n",
      "\n",
      "\n",
      "Class: Snail\n",
      "{'accuracy': 0.4986149584487535,\n",
      " 'f1': 0.007312614259597807,\n",
      " 'precision': 1.0,\n",
      " 'recall': 0.003669724770642202}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize lists to store predictions and ground truth labels\n",
    "all_predictions = []\n",
    "all_ground_truth = []\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Iterate through the DataLoader\n",
    "for inputs, labels in dataset_loader:\n",
    "    # Move inputs to the device\n",
    "    inputs = inputs.to(device)\n",
    "    \n",
    "    # Perform inference\n",
    "    with torch.no_grad():\n",
    "        outputs = model(inputs)\n",
    "\n",
    "    # Apply softmax to the model's output along the specified dimension\n",
    "    probabilities = torch.nn.functional.softmax(outputs, dim=1)\n",
    "    \n",
    "    # Convert model outputs to numpy array\n",
    "    predictions = probabilities.squeeze().cpu().numpy()\n",
    "\n",
    "    # Convert labels tensor to numpy array\n",
    "    ground_truth_indices = labels.numpy()\n",
    "\n",
    "    # Convert ground truth indices to one-hot encoded vectors\n",
    "    ground_truth_one_hot = torch.nn.functional.one_hot(torch.tensor(ground_truth_indices), num_classes=len(CHOSEN_CLASSES)).numpy()\n",
    "\n",
    "    # Filter predictions for chosen classes\n",
    "    chosen_predictions = predictions[:, [classes.index(f\"{class_name.lower()}\" + \"\\n\") for class_name in CHOSEN_CLASSES]]\n",
    "\n",
    "    # Append predictions and ground truth to the lists\n",
    "    all_predictions.append(chosen_predictions)\n",
    "    all_ground_truth.append(ground_truth_one_hot)\n",
    "\n",
    "# Pad all arrays to have the same number of rows (BATCH_SIZE)\n",
    "all_predictions_padded = [np.pad(x, ((0, BATCH_SIZE - len(x)), (0, 0))) for x in all_predictions]\n",
    "\n",
    "# Use calculate_metrics function\n",
    "metrics = calculate_metrics(all_ground_truth, all_predictions_padded, threshold=THRESHOLD)\n",
    "\n",
    "# Print results\n",
    "print(f\"Threshold: {THRESHOLD}\\n\")\n",
    "for i in metrics:\n",
    "    print(f\"Class: {i}\")\n",
    "    pprint.pprint(metrics[i])\n",
    "    print('\\n')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
